# Docker基本使用

## 镜像构建

要构建 Docker 镜像，需要创建一个 Dockerfile 文件，该文件描述了镜像的构建方式。Dockerfile 包含了一系列指令，用于从一个基础镜像中创建一个新的镜像，并在其中添加所需的组件和应用程序。

以下是一个简单的 Dockerfile 示例：

```sh
FROM ubuntu:latest
RUN apt-get update && apt-get install -y nginx
COPY index.html /var/www/html/
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

该 Dockerfile 从最新的 Ubuntu 镜像开始，安装了 Nginx Web 服务器，并将 `index.html` 文件复制到 Web 服务器的默认文档根目录。接下来，它暴露了容器的 80 端口，并启动 Nginx 服务器。

要构建该镜像，请在包含 Dockerfile 的目录中运行以下命令：

```sh
docker build -t my-image .
```

该命令将使用 Dockerfile 中的指令构建一个名为 `my-image` 的新镜像，并将其标记为 `latest` 版本。`-t` 标志用于指定镜像的名称和标签。`.` 表示 Dockerfile 文件在当前目录中。

构建过程可能需要一些时间，具体取决于 Dockerfile 中的指令和所需的组件。完成后，可以使用 `docker images` 命令查看的新镜像。



## 启动镜像

要启动 Docker 镜像，您需要使用 `docker run` 命令。以下是一个简单的示例：

```sh
docker run -d --name my-container my-image
```

该命令将使用 `my-image` 镜像创建一个名为 `my-container` 的新容器，并在后台运行。`-d` 标志表示容器应该在后台运行，而不是在控制台中运行。`--name` 标志用于指定容器的名称。

您可以使用 `docker ps` 命令查看正在运行的容器。如果您想在控制台中查看容器的输出，可以使用 `docker logs` 命令：

```sh
docker logs my-container
```

如果您需要进入正在运行的容器的 shell，可以使用 `docker exec` 命令：

```sh
docker exec -it my-container /bin/bash
```

这将在容器中启动一个新的 Bash shell，允许您执行命令和查看文件系统。



## 容器导出镜像

要将容器导出为镜像，可以使用 `docker commit` 命令。该命令将当前运行的容器创建成一个新的镜像，并将其保存到本地镜像仓库中。具体步骤如下：

1. 运行需要导出的容器：`docker run -it <image_name>`

2. 在容器中进行一些修改和配置，确保容器中包含了你想要保存的内容。

3. 在另一个终端窗口中运行 `docker ps` 命令，找到容器的 ID。

4. 使用 `docker commit` 命令将容器导出为镜像。命令格式如下：

   ```sh
   docker commit <container_id> <new_image_name>
   ```

   其中，`<container_id>` 是容器的 ID，`<new_image_name>` 是新的镜像名称。

5. 等待镜像创建完成后，可以使用 `docker images` 命令查看本地镜像仓库中的所有镜像，确认新的镜像已经成功导出。

注意：使用 `docker commit` 命令导出的镜像可能不太稳定，因为它可能包含一些不必要的文件和配置。因此，最好还是通过 Dockerfile 来构建镜像。



## 上传镜像

**账号**：exlobin
密码：bin.xu@2021

要上传 Docker 镜像，需要先将本地的镜像推送到 Docker Hub 或其他 Docker 镜像仓库中。推送镜像的步骤如下：

1. 登录 Docker Hub 或其他 Docker 镜像仓库：

   ```sh
   docker login
   ```

   执行该命令后，会提示输入 Docker Hub 或其他 Docker 镜像仓库的用户名和密码。

2. 标记要上传的镜像：

   ```sh
   docker tag <local_image> <registry>/<username>/<repo_name>:<tag>
   ```

   其中，`<local_image>` 是本地要上传的镜像名称和标签，`<registry>` 是 Docker 镜像仓库的地址（如果是 Docker Hub，可以省略），`<username>` 是 Docker 镜像仓库的用户名，`<repo_name>` 是要上传到的仓库名称，`<tag>` 是镜像的标签。

   例如，要上传本地的 `myimage:1.0` 镜像到 Docker Hub 的 `myrepo` 仓库中，可以执行以下命令：

   ```sh
   docker tag myimage:1.0 myusername/myrepo:1.0
   ```

3. 推送镜像到 Docker 镜像仓库：

   ```sh
   docker push <registry>/<username>/<repo_name>:<tag>
   ```

   其中，`<registry>`、`<username>`、`<repo_name>` 和 `<tag>` 的含义同上。

   例如，要将 `myimage:1.0` 镜像推送到 Docker Hub 的 `myrepo` 仓库中，可以执行以下命令：

   ```sh
   docker push myusername/myrepo:1.0
   ```

   执行该命令后，Docker 会将本地的镜像推送到 Docker Hub 或其他 Docker 镜像仓库中。上传成功后，其他用户就可以通过 `docker pull` 命令从 Docker 镜像仓库中获取该镜像。
   
   

## 查看容器日志

要实时查看 Docker 容器中的最新日志，可以使用 `docker logs` 命令的 `-f` 参数。例如，以下命令将显示名为 `mycontainer` 的容器的最新 100 行日志，并在容器继续输出日志时实时更新日志输出：

```sh
docker logs -f --tail 100 mycontainer
```

其中，`--tail` 参数指定要显示的最后几行日志，默认为所有日志。

请注意，使用 `-f` 参数将使命令保持运行状态，直到您按下 `Ctrl + C` 停止命令。如果您只想查看最新 100 行日志，可以在命令末尾添加 `| tail -n 100`，例如：

```sh
docker logs -f mycontainer | tail -n 100
```

这将仅显示最新 100 行日志，并在容器继续输出日志时实时更新输出。



## 容器运行状态查看

`docker ps` 和 `docker ps -a` 都是用来列出 Docker 容器的命令。

`docker ps` 只会列出正在运行的容器，而不会列出已停止的容器。

`docker ps -a` 会列出所有的容器，包括正在运行的容器和已停止的容器。



## 退出所有停止的容器

可以使用以下命令退出所有已停止的容器：

```sh
docker container stop $(docker container ls -aq)
```

这个命令会先列出所有容器的 ID，然后将这些 ID 传递给 `docker container stop` 命令，从而停止所有容器。



## 退出所有已退出的容器

可以使用以下命令退出所有已退出的容器：

```sh
docker container rm $(docker container ls -aqf status=exited)
```

这个命令会先列出所有已退出的容器的 ID，然后将这些 ID 传递给 `docker container rm` 命令，从而删除所有已退出的容器。



## docker-compose相关操作



### 集群初始化

`docker swarm init` 是一个命令，用于初始化 Docker Swarm 集群。Docker Swarm 是 Docker 官方提供的容器编排工具，用于管理多个 Docker 容器的部署和扩展。通过初始化 Docker Swarm 集群，可以将多个 Docker 主机组成一个集群，从而实现容器的高可用性和负载均衡。

`docker swarm init` 命令会在当前主机上创建一个 Swarm Manager 节点，并生成一个加入 Swarm 集群的命令，可以将这个命令复制到其他主机上，让它们加入到 Swarm 集群中。在 Swarm 集群中，可以使用 `docker service` 命令来管理容器服务，例如创建、更新和删除服务，以及在集群中进行负载均衡和故障转移等操作。



### 查看 token

要查看 Docker Swarm 的 token，您可以在 Swarm Manager 节点上运行以下命令：

```sh
docker swarm join-token worker
```

这将输出一个命令，您可以将其复制并在要加入 Swarm 的节点上运行，以加入 Swarm。如果您想查看 manager 节点的 token，可以将上述命令中的 "worker" 替换为 "manager"。



### 集群添加节点

在 Docker Swarm 集群中，每个节点都需要加入集群才能参与容器的部署和运行。为了保证集群的安全性，Docker Swarm 采用了一种基于令牌（token）的认证机制，只有拥有有效令牌的节点才能加入集群。

要查看 Docker Swarm 集群的令牌，可以使用以下命令：

```sh
docker swarm join-token <manager|worker>
```

其中，`<manager|worker>` 指定要查看的令牌类型，可以是管理节点（manager）或工作节点（worker）。执行该命令后，会输出一个包含令牌信息的命令行，例如：

```sh
docker swarm join --token SWMTKN-xxx-xxx-xxx-xxx <IP_ADDRESS>:2377
```

其中，`SWMTKN-xxx-xxx-xxx-xxx` 是令牌值，`<IP_ADDRESS>` 是管理节点的 IP 地址。将该命令行复制到要加入集群的节点上执行，即可将该节点加入 Docker Swarm 集群。



要向 Docker Swarm 集群添加节点，可以使用以下步骤：

1. 在要添加到集群的新节点上安装 Docker。
2. 在 Swarm Manager 节点上生成加入 Swarm 集群的命令：

   ```sh
   docker swarm join-token worker
   ```

   这个命令会生成一个加入 Swarm 集群的命令，类似于：

   ```sh
   docker swarm join --token <token> <ip-address>:<port>
   ```

3. 在新节点上运行上一步生成的加入 Swarm 集群的命令，将新节点加入到 Swarm 集群中。

   ```sh
   docker swarm join --token <token> <ip-address>:<port>
   ```

4. 在 Swarm Manager 节点上运行 `docker node ls` 命令，可以查看当前 Swarm 集群中的节点列表，包括新添加的节点。

   ```sh
   docker node ls
   ```

5. 在 Swarm 集群中部署服务时，新添加的节点将会参与服务的部署和运行，从而实现容器的高可用性和负载均衡。



### 退出节点

如果你想要退出 Docker Swarm 集群的节点，可以使用 `docker swarm leave` 命令。该命令会将当前节点从 Swarm 集群中移除，并停止所有在该节点上运行的服务和容器。

如果你只是想暂时离开 Swarm 集群，可以使用 `docker swarm leave --force` 命令。该命令会将当前节点从 Swarm 集群中强制移除，但不会停止在该节点上运行的服务和容器。这样，你可以在需要的时候重新加入集群。

如果你想要完全退出 Swarm 集群，可以使用 `docker swarm leave --force` 命令，并在退出之后使用 `docker swarm leave --force --grace-period 0` 命令来立即停止在该节点上运行的服务和容器。这样，你就可以安全地从 Swarm 集群中移除节点了。



### 统计 Docker Swarm 容器运行状态

```sh
docker node ps $(docker node ls -q) --filter "desired-state=running"
```

这个命令会列出所有节点上正在运行的容器。其中，`docker node ls -q` 用于获取所有节点的 ID，`--filter "desired-state=running"` 用于筛选出状态为 running 的容器。



# VPN 集群服务



- 项目地址：[点击跳转](http://code.deepbiogroup.com/data/vpn_auto_switch/-/tree/master/)

- 节点切换脚本

  - 节点切换已配置地址：[点击跳转](http://192.168.1.33/#/tasklist/26/pname/VPN节点切换)

  - 使用方法详见：[ README.md](http://code.deepbiogroup.com/data/vpn_auto_switch/-/blob/master/README.md) 

  - 已配置截图

    ![截屏2023-06-12 13.01.27](https://p.ipic.vip/7jwmtt.png)

    

- 集群服务：[点击跳转](http://code.deepbiogroup.com/data/vpn_auto_switch/-/tree/master/service)

- clash 更新订阅

  - 使用方法见 README.md [点击跳转](http://code.deepbiogroup.com/data/vpn_auto_switch/-/tree/master/clash_image_build)



# feaplat爬虫管理系统

文档地址：[点击跳转](https://feapder.com/#/feapder_platform/feaplat)



## 项目部署地址

```shell
ssh group_data@192.168.1.33 # password: groupdata

cd feaplat
pwd
/data02/home/group_data/feaplat
```



## 目录结构

├── conf
│   └── influxdb.conf
├── docker-compose-without-network.yaml
├── docker-compose.yaml
├── feapder_dockerfile
├── README.md
└── .env



## 文件说明

.env

经常会更新的是爬虫镜像版本，当端口冲突时更改端口。

```shell
# 前端端口
FRONT_PORT=80
# 后端端口
BACKEND_PORT=8000
# MYSQL端口
MYSQL_PORT=33306
# REDIS 端口
REDIS_PORT=6379
# 后端worker数
BACKEND_WORKER=5
# 前端镜像
FRONT_IMAGE=registry.cn-hangzhou.aliyuncs.com/feapderd/feapder_front:2.5
# 后端镜像
BACKEND_IMAGE=registry.cn-hangzhou.aliyuncs.com/feapderd/feapder_backend:3.6
# 爬虫镜像
SPIDER_IMAGE=exlobin/feapder:1.8.8
# 监控系统端口配置
INFLUXDB_PORT_TCP=8086
INFLUXDB_PORT_UDP=8089
GRAFANA_PORT=3001

# 后端地址及监控数据库地址，若爬虫节点与后端连不上，则将此处的值都改成内网ip即可
BACKEND_HOST=feapder_backend
INFLUXDB_HOST=feapder_influxdb

# 监控数据库 INFLUXDB 配置
INFLUXDB_DB=feapder
INFLUXDB_ADMIN_USER=root
INFLUXDB_ADMIN_PASSWORD=root

# 下面这些配置可在feaplat管理系统页面上配置，这里不用改
# 授权码
AUTHORIZATION_CODE=
# git ssh 私钥， 直接复制密钥的值 换行改为空格
GIT_SSH_PRIVATE_KEY=
```



## 常用命令

```shell
# 查看节点信息
docker node ls
# 设置管理平台节点不跑任任务
docker node update --availability drain <NODE-ID>
# 重新激活drain节点——设置后更新feaplat时需要重新激活
docker node update --availability active <NODE-ID>
```



# exlobin/feapder:1.8.8镜像说明

该镜像内置 chrome 、playwright，镜像重做时务必安装这两个依赖

当前在运行的爬虫1.8.8 完全兼容，当前时间为 2023 年 6 月 12 日



# Snowflake服务

项目地址：[点击跳转](http://code.deepbiogroup.com/data/snowflake)



# fastquery源码查询服务

项目地址：[点击跳转](http://code.deepbiogroup.com/data/fast_query_image)



# 文献采集（e-article）

文献一个季度更新一次

项目地址：[点击跳转](http://code.deepbiogroup.com/data/ncbi_daily_update)



项目概述：文献任务来自于 pmc 发布的 csv 更新文件和 NCBI 发布的压缩包。

1. 采集每日更新数据（pmc &ncbi 的文件下载链接）
2. 文件下载
3.  解析ncbi 压缩包中的 xml并入库
4. 清洗出需要下载的 pdf



## 任务采集

PMC每日发布采集：[点击跳转配置页](http://192.168.1.33/#/tasklist/50/pname/Ncbi文献信息&PMC文献爬虫)

https://ftp.ncbi.nlm.nih.gov/pub/pmc/

​	oa_file_list

NCBI 压缩包地址采集：[点击跳转配置页](http://192.168.1.33/#/tasklist/50/pname/Ncbi文献信息&PMC文献爬虫)

https://ftp.ncbi.nlm.nih.gov/pubmed/updatefiles/



## pmc 压缩包下载

支持多线程断点续传

项目地址

​		88 服务器 ，路径：`/data/share/xubin/ncbi_paper`

启动命令：`python pmcxml_download.py`

 文件存储路径：`/backup/share/groupdata/ncbi_pmc_rar/pmc`



## NCBI压缩包解析服务



<!--连接88 服务器运行以下命令启动解析服务-->

启动容器

```shell
docker run  -itd -e MYSQL_IP=192.168.1.88 -e MYSQL_PORT=3309 -e MYSQL_DB=NcbiDailyUpdate -e MYSQL_USER_NAME=xubin -e MYSQL_USER_PASS=bin.xu@2021 -e REDISDB_IP_PORTS=192.168.1.89:6379 -e REDISDB_DB=0 --restart=always -v /backup/share/group_data/ncbi_rar:/data -v /data/share/xubin/ncbi_daily_parse:/ncbi_daily_parse --privileged=true --name=ncbi-daily-parse-service  ncbi-service:1.1.0
```

进入容器启动解析

```sh
docker exec -it ncbi-daily-parse-service bash
cd ncbi_daily_parse/
python main.py 
```

`-e MYSQL_IP=192.168.1.88`为环境变量

`-v /backup/share/group_data/ncbi_rar:/data ` 为映射路径

`--restart=always` 表示容器应该始终在 Docker 守护进程启动时自动启动，并在容器停止或崩溃时自动重新启动

`--privileged=true` 是 Docker 运行容器时的一个选项，它允许容器在特权模式下运行。在特权模式下，容器将拥有主机系统的所有权限，包括访问主机的设备和文件系统。这意味着容器可以执行一些需要特权访问的操作，例如加载内核模块、更改主机网络配置等。但是，需要注意的是，使用 `--privileged=true` 选项会增加容器被攻击的风险。因此，建议仅在必要时使用该选项，并且要确保容器中的应用程序和服务是安全的。



##  PDF 下载

每年 pdf 会开放的数量相对较少，需先解析ncbi 压缩包中的 xml，提取 doi，先剔除已采集的文章，再剔除pmc html 和 pmc xml文章。剔除之后的 doi 与 `https://sci.bban.top/pdf/{doi}.pdf?download=true`进行拼接，获得pdf 下载地址。若无该条链接下载资源，可以跳过，过段时间重新下载。已下载的 pdf 明细在 `PaperPdfDownloadDoneRecord` 表中。



项目地址：[点击跳转](http://code.deepbiogroup.com/data/paper_pdf_download_2023)

​		88 服务器，路径`/data/share/xubin/paper_pdf_download_2023`

启动命令：`python main.py`







# 产品采集（e-data）

项目地址：[点击跳转](http://code.deepbiogroup.com/data/product_batch_spider)



# 各省市项目附件下载

项目地址：[点击跳转](http://code.deepbiogroup.com/data/research_project_annex_spider)



# 国内代理



## Malenia 代理

http://haproxy.iinti.cn:8000/#/dashboard

账号 ：13564157050
密码：bin.xu@2021

该网站充值需要加管理员微信进行转账

#### 优点

- 不限制并发限制带宽，增加带宽联系管理员
- 性价比高
- 不限制国外站点访问

#### 缺点

- 响应较慢
- 不用时需要手动暂停，否则会持续收费



## 快代理

https://www.kuaidaili.com

账号 ：13564157050
密码：bin.xu@2021

#### 优点

- ip资源丰富

#### 缺点

- 境外站点需要找客服解除屏蔽



# 发票抬头

名称： 迪普佰奥生物科技（上海）股份有限公司
统一社会信用代码：91310115MA1K4AW42K
组织机构识别代码：MA1K4AW42
地址：上海市闵行区申南路515号2幢604室
联系电话：13621973941
开户银行：中国建设银行股份有限公司上海莘松路支行
帐号： 31050180470000001023



# OpenAI-SB

余额充值：https://www.feijiji.com/

官方文档：https://openai-sb.com/

该网站不提供发票，支付账单截图报销

## Api_key

```
sb-655ad790fd4904c45c4e729f350f6a88
```

## 查询 API_KEY 余额

```
https://api.openai-sb.com/sb-api/user/status?api_key=sb-655ad790fd4904c45c4e729f350f6a88
```

